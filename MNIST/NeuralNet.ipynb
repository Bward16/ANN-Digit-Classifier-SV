{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MZcxuXMB1L7y",
        "outputId": "22ff8484-9e9b-474c-e42d-ce45eafad81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proceed (Y/n)? "
          ]
        }
      ],
      "source": [
        "\n",
        "!pip uninstall -q tensorflow==2.16.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX-_zcT7pSrv",
        "outputId": "965784b1-9cdc-411a-eff6-2003b4faa6e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m987.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Rou_L71uHk",
        "outputId": "a3edb50f-c3a5-4de5-e5d7-cd25e176d4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)  # Should print 2.16.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcg7DNc4kw0v",
        "outputId": "f32d2e0c-4ef3-434a-8caa-4d9989c0ddb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "422/422 [==============================] - 7s 11ms/step - loss: 0.8932 - accuracy: 0.7233 - val_loss: 0.2869 - val_accuracy: 0.9217\n",
            "Epoch 2/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3041 - accuracy: 0.9132 - val_loss: 0.2304 - val_accuracy: 0.9338\n",
            "Epoch 3/20\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2386 - accuracy: 0.9304 - val_loss: 0.1747 - val_accuracy: 0.9497\n",
            "Epoch 4/20\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.2038 - accuracy: 0.9407 - val_loss: 0.1527 - val_accuracy: 0.9590\n",
            "Epoch 5/20\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1772 - accuracy: 0.9478 - val_loss: 0.1280 - val_accuracy: 0.9615\n",
            "Epoch 6/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1586 - accuracy: 0.9527 - val_loss: 0.1304 - val_accuracy: 0.9610\n",
            "Epoch 7/20\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1462 - accuracy: 0.9566 - val_loss: 0.1184 - val_accuracy: 0.9657\n",
            "Epoch 8/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1399 - accuracy: 0.9576 - val_loss: 0.1113 - val_accuracy: 0.9678\n",
            "Epoch 9/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1265 - accuracy: 0.9625 - val_loss: 0.1112 - val_accuracy: 0.9678\n",
            "Epoch 10/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1176 - accuracy: 0.9642 - val_loss: 0.1105 - val_accuracy: 0.9692\n",
            "Epoch 11/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.1115 - accuracy: 0.9657 - val_loss: 0.1038 - val_accuracy: 0.9687\n",
            "Epoch 12/20\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1053 - accuracy: 0.9681 - val_loss: 0.1157 - val_accuracy: 0.9670\n",
            "Epoch 13/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1022 - accuracy: 0.9684 - val_loss: 0.1252 - val_accuracy: 0.9633\n",
            "Epoch 14/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0940 - accuracy: 0.9709 - val_loss: 0.1007 - val_accuracy: 0.9703\n",
            "Epoch 15/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0878 - accuracy: 0.9730 - val_loss: 0.1083 - val_accuracy: 0.9693\n",
            "Epoch 16/20\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0875 - accuracy: 0.9732 - val_loss: 0.1266 - val_accuracy: 0.9630\n",
            "Epoch 17/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0830 - accuracy: 0.9741 - val_loss: 0.1132 - val_accuracy: 0.9682\n",
            "Epoch 18/20\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0778 - accuracy: 0.9753 - val_loss: 0.0964 - val_accuracy: 0.9730\n",
            "Epoch 19/20\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.0776 - accuracy: 0.9756 - val_loss: 0.1127 - val_accuracy: 0.9680\n",
            "Epoch 20/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0730 - accuracy: 0.9772 - val_loss: 0.1079 - val_accuracy: 0.9708\n",
            " 62/313 [====>.........................] - ETA: 0s - loss: 0.1558 - accuracy: 0.9541"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(784,)))\n",
        "    model.add(layers.Dense(50, activation='relu', name='dense'))\n",
        "    model.add(layers.Dense(20, activation='relu', name='dense_1'))\n",
        "    model.add(layers.Dense(10, activation='relu', name='dense_2'))\n",
        "    model.add(layers.Dense(10, activation='relu', name='dense_3'))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.1)\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
        "\n",
        "\n",
        "layer_weights = {}\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, layers.Dense):\n",
        "        weights, biases = layer.get_weights()\n",
        "        layer_weights[layer.name] = {'weights': weights, 'biases': biases}\n",
        "        print(f\"Layer name: {layer.name}\")\n",
        "        print(f\"Weights shape: {weights.shape}\")\n",
        "        print(f\"Biases shape: {biases.shape}\")\n",
        "\n",
        "# Representative dataset generator for quantization\n",
        "def representative_data_gen():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
        "        yield [tf.dtypes.cast(input_value, tf.float32)]\n",
        "\n",
        "# Create a concrete function from the Keras model\n",
        "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 784], dtype=tf.float32)])\n",
        "def model_func(inputs):\n",
        "    return model(inputs)\n",
        "\n",
        "concrete_func = model_func.get_concrete_function()\n",
        "\n",
        "# Convert the model to a TensorFlow Lite model with int8 quantization\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "quantized_tflite_model = converter.convert()\n",
        "\n",
        "with open(\"quantized_model_scaled.tflite\", \"wb\") as f:\n",
        "    f.write(quantized_tflite_model)\n",
        "\n",
        "# Function to save the weights and biases of the quantized model\n",
        "def save_quantized_weights_and_biases(tflite_model, filename, layer_weights):\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    tensor_details = interpreter.get_tensor_details()\n",
        "\n",
        "    print(f\"Number of tensors in the quantized model: {len(tensor_details)}\")\n",
        "    print(f\"Number of layers in Keras model: {len(layer_weights)}\")\n",
        "\n",
        "    with open(filename + '_quantized_params.txt', \"w\") as file:\n",
        "        for i, tensor_detail in enumerate(tensor_details):\n",
        "            tensor_name = tensor_detail['name']\n",
        "            try:\n",
        "                tensor = interpreter.get_tensor(tensor_detail['index'])\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping tensor {tensor_name} due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "            header = f\"{tensor_name} (index: {i})\"\n",
        "            if \"BiasAdd/ReadVariableOp/resource\" in tensor_name:\n",
        "                layer_name = tensor_name.split('/')[1]\n",
        "                header += f\", corresponds to layer: {layer_name} biases\"\n",
        "            elif \"MatMul\" in tensor_name and \"BiasAdd\" not in tensor_name:\n",
        "                layer_name = tensor_name.split('/')[1]\n",
        "                header += f\", corresponds to layer: {layer_name} weights\"\n",
        "\n",
        "            file.write(f\"# {header}\\n\")\n",
        "            np.savetxt(file, tensor)\n",
        "\n",
        "# Save the weights and biases\n",
        "save_quantized_weights_and_biases(quantized_tflite_model, \"quantized_model_scaled\", layer_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9NyP6RIkw3h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R0rqcV5kw9q",
        "outputId": "55982f47-24a4-404e-9be1-bdc74836c295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "422/422 [==============================] - 4s 7ms/step - loss: 0.8676 - accuracy: 0.7275 - val_loss: 0.4597 - val_accuracy: 0.8978\n",
            "Epoch 2/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3199 - accuracy: 0.9098 - val_loss: 0.2019 - val_accuracy: 0.9423\n",
            "Epoch 3/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2342 - accuracy: 0.9321 - val_loss: 0.1650 - val_accuracy: 0.9552\n",
            "Epoch 4/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1987 - accuracy: 0.9422 - val_loss: 0.1489 - val_accuracy: 0.9582\n",
            "Epoch 5/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1748 - accuracy: 0.9488 - val_loss: 0.1349 - val_accuracy: 0.9617\n",
            "Epoch 6/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1613 - accuracy: 0.9517 - val_loss: 0.1379 - val_accuracy: 0.9583\n",
            "Epoch 7/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.1464 - accuracy: 0.9566 - val_loss: 0.1257 - val_accuracy: 0.9643\n",
            "Epoch 8/20\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.1372 - accuracy: 0.9581 - val_loss: 0.1367 - val_accuracy: 0.9588\n",
            "Epoch 9/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1300 - accuracy: 0.9601 - val_loss: 0.1165 - val_accuracy: 0.9667\n",
            "Epoch 10/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1250 - accuracy: 0.9627 - val_loss: 0.1375 - val_accuracy: 0.9612\n",
            "Epoch 11/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1191 - accuracy: 0.9635 - val_loss: 0.1141 - val_accuracy: 0.9697\n",
            "Epoch 12/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1121 - accuracy: 0.9658 - val_loss: 0.1332 - val_accuracy: 0.9627\n",
            "Epoch 13/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1058 - accuracy: 0.9681 - val_loss: 0.1313 - val_accuracy: 0.9647\n",
            "Epoch 14/20\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1010 - accuracy: 0.9688 - val_loss: 0.1149 - val_accuracy: 0.9682\n",
            "Epoch 15/20\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.0992 - accuracy: 0.9697 - val_loss: 0.1247 - val_accuracy: 0.9655\n",
            "Epoch 16/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0947 - accuracy: 0.9713 - val_loss: 0.1110 - val_accuracy: 0.9700\n",
            "Epoch 17/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.1198 - val_accuracy: 0.9668\n",
            "Epoch 18/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0879 - accuracy: 0.9726 - val_loss: 0.1232 - val_accuracy: 0.9682\n",
            "Epoch 19/20\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0870 - accuracy: 0.9728 - val_loss: 0.1290 - val_accuracy: 0.9655\n",
            "Epoch 20/20\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0844 - accuracy: 0.9742 - val_loss: 0.1245 - val_accuracy: 0.9658\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1365 - accuracy: 0.9622\n",
            "Test loss: 0.13648821413516998, Test accuracy: 0.9621999859809875\n",
            "Layer name: dense\n",
            "Weights shape: (784, 50)\n",
            "Biases shape: (50,)\n",
            "Layer name: dense_1\n",
            "Weights shape: (50, 20)\n",
            "Biases shape: (20,)\n",
            "Layer name: dense_2\n",
            "Weights shape: (20, 10)\n",
            "Biases shape: (10,)\n",
            "Layer name: dense_3\n",
            "Weights shape: (10, 10)\n",
            "Biases shape: (10,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor length is: 10\n",
            "Tensor length is: 10\n",
            "Tensor length is: 10\n",
            "Tensor length is: 10\n",
            "Tensor length is: 20\n",
            "Tensor length is: 20\n",
            "Tensor length is: 50\n",
            "Tensor length is: 50\n",
            "Skipping tensor sequential_2/dense/MatMul;sequential_2/dense/Relu;sequential_2/dense/BiasAdd due to error: Tensor data is null. Run allocate_tensors() first\n",
            "Skipping tensor sequential_2/dense_1/MatMul;sequential_2/dense_1/Relu;sequential_2/dense_1/BiasAdd due to error: Tensor data is null. Run allocate_tensors() first\n",
            "Skipping tensor sequential_2/dense_2/MatMul;sequential_2/dense_2/Relu;sequential_2/dense_2/BiasAdd due to error: Tensor data is null. Run allocate_tensors() first\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(784,)))\n",
        "    model.add(layers.Dense(50, activation='relu', name='dense'))\n",
        "    model.add(layers.Dense(20, activation='relu', name='dense_1'))\n",
        "    model.add(layers.Dense(10, activation='relu', name='dense_2'))\n",
        "    model.add(layers.Dense(10, activation='relu', name='dense_3'))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.1)\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
        "\n",
        "layer_weights = {}\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, layers.Dense):\n",
        "        weights, biases = layer.get_weights()\n",
        "        layer_weights[layer.name] = {'weights': weights, 'biases': biases}\n",
        "        print(f\"Layer name: {layer.name}\")\n",
        "        print(f\"Weights shape: {weights.shape}\")\n",
        "        print(f\"Biases shape: {biases.shape}\")\n",
        "\n",
        "# Representative dataset generator for quantization\n",
        "def representative_data_gen():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
        "        yield [tf.dtypes.cast(input_value, tf.float32)]\n",
        "\n",
        "# Create a concrete function from the Keras model\n",
        "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 784], dtype=tf.float32)])\n",
        "def model_func(inputs):\n",
        "    return model(inputs)\n",
        "\n",
        "concrete_func = model_func.get_concrete_function()\n",
        "\n",
        "# Convert the model to a TensorFlow Lite model with int8 quantization\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "quantized_tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "with open(\"quantized_model_int8.tflite\", \"wb\") as f:\n",
        "    f.write(quantized_tflite_model)\n",
        "\n",
        "# Function to save the weights and biases of the quantized model\n",
        "def save_quantized_weights_and_biases(tflite_model, filename):\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    tensor_details = interpreter.get_tensor_details()\n",
        "\n",
        "    with open(filename + '_quantized_params.txt', \"w\") as file:\n",
        "        for tensor_detail in tensor_details:\n",
        "            tensor_name = tensor_detail['name']\n",
        "            if \"BiasAdd\" in tensor_name or \"MatMul\" in tensor_name:\n",
        "                try:\n",
        "                    tensor = interpreter.get_tensor(tensor_detail['index'])\n",
        "                    # Check if tensor has valid data\n",
        "                    if tensor is not None:\n",
        "                        header = f\"{tensor_name} (index: {tensor_detail['index']})\"\n",
        "                        print(f\"Tensor length is: {len(tensor)}\")\n",
        "                        if \"BiasAdd\" in tensor_name:\n",
        "                            layer_name = tensor_name.split('/')[1]\n",
        "                            header += f\", corresponds to layer: {layer_name} biases\"\n",
        "                        elif \"MatMul\" in tensor_name:\n",
        "                            layer_name = tensor_name.split('/')[1]\n",
        "                            header += f\", corresponds to layer: {layer_name} weights\"\n",
        "\n",
        "                        file.write(f\"# {header}\\n\")\n",
        "                        np.savetxt(file, tensor)\n",
        "                except ValueError as e:\n",
        "                    print(f\"Skipping tensor {tensor_name} due to error: {e}\")\n",
        "\n",
        "# Save the weights and biases\n",
        "save_quantized_weights_and_biases(quantized_tflite_model, \"quantized_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "oUZuHVqUEWLY",
        "outputId": "f40eef9c-5ea2-408a-b6fc-0af6e740432e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'lines' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b3618ba97027>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcurrent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lines' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "weights_count = {\n",
        "    'dense': 0,\n",
        "    'dense_1': 0,\n",
        "    'dense_2': 0,\n",
        "    'dense_3': 0\n",
        "}\n",
        "biases_count = {\n",
        "    'dense': 0,\n",
        "    'dense_1': 0,\n",
        "    'dense_2': 0,\n",
        "    'dense_3': 0\n",
        "}\n",
        "\n",
        "\n",
        "current_layer = None\n",
        "current_type = None\n",
        "\n",
        "for line in lines:\n",
        "    if line.startswith('#'):\n",
        "        if 'weights' in line:\n",
        "            current_layer = line.split('corresponds to layer: ')[1].split(' weights')[0]\n",
        "            current_type = 'weights'\n",
        "        elif 'biases' in line:\n",
        "            current_layer = line.split('corresponds to layer: ')[1].split(' biases')[0]\n",
        "            current_type = 'biases'\n",
        "    else:\n",
        "        if current_layer and current_type:\n",
        "            values = line.strip().split()\n",
        "            num_values = len(values)\n",
        "            if current_type == 'weights':\n",
        "                weights_count[current_layer] += num_values\n",
        "            elif current_type == 'biases':\n",
        "                biases_count[current_layer] += num_values\n",
        "\n",
        "# Print the counts\n",
        "print(\"Weights count:\", weights_count)\n",
        "print(\"Biases count:\", biases_count)\n",
        "\n",
        "# Verify counts\n",
        "expected_weights_count = {\n",
        "    'dense': 784 * 50,\n",
        "    'dense_1': 50 * 20,\n",
        "    'dense_2': 20 * 10,\n",
        "    'dense_3': 10 * 10\n",
        "}\n",
        "expected_biases_count = {\n",
        "    'dense': 50,\n",
        "    'dense_1': 20,\n",
        "    'dense_2': 10,\n",
        "    'dense_3': 10\n",
        "}\n",
        "\n",
        "print(\"Expected weights count:\", expected_weights_count)\n",
        "print(\"Expected biases count:\", expected_biases_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnvUfmkJHl2D",
        "outputId": "8414b707-a66a-44ba-9c23-fcca216f95a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor name: inputs\n",
            "  Scale: [0.00392157]\n",
            "  Zero point: [-128]\n",
            "Tensor name: sequential_10/dense_3/BiasAdd/ReadVariableOp/resource\n",
            "  Scale: [0.00125457]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense_3/MatMul\n",
            "  Scale: [0.0096693]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense_2/BiasAdd/ReadVariableOp/resource\n",
            "  Scale: [0.00084419]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense_2/MatMul\n",
            "  Scale: [0.00900361]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense_1/BiasAdd/ReadVariableOp/resource\n",
            "  Scale: [0.00038594]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense_1/MatMul\n",
            "  Scale: [0.00877394]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense/BiasAdd/ReadVariableOp/resource\n",
            "  Scale: [2.9944636e-05]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense/MatMul\n",
            "  Scale: [0.00763588]\n",
            "  Zero point: [0]\n",
            "Tensor name: sequential_10/dense/MatMul;sequential_10/dense/Relu;sequential_10/dense/BiasAdd\n",
            "  Scale: [0.04398748]\n",
            "  Zero point: [-128]\n",
            "Tensor name: sequential_10/dense_1/MatMul;sequential_10/dense_1/Relu;sequential_10/dense_1/BiasAdd\n",
            "  Scale: [0.09376158]\n",
            "  Zero point: [-128]\n",
            "Tensor name: sequential_10/dense_2/MatMul;sequential_10/dense_2/Relu;sequential_10/dense_2/BiasAdd\n",
            "  Scale: [0.12974793]\n",
            "  Zero point: [-128]\n",
            "Tensor name: Identity\n",
            "  Scale: [0.10826657]\n",
            "  Zero point: [-128]\n"
          ]
        }
      ],
      "source": [
        "def print_scaling_factors(tflite_model):\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    tensor_details = interpreter.get_tensor_details()\n",
        "\n",
        "    for tensor_detail in tensor_details:\n",
        "        tensor_name = tensor_detail['name']\n",
        "        quant_params = tensor_detail['quantization_parameters']\n",
        "        scale = quant_params['scales']\n",
        "        zero_point = quant_params['zero_points']\n",
        "        if scale.size > 0 and zero_point.size > 0:\n",
        "            print(f\"Tensor name: {tensor_name}\")\n",
        "            print(f\"  Scale: {scale}\")\n",
        "            print(f\"  Zero point: {zero_point}\")\n",
        "\n",
        "# Print the scaling factors\n",
        "print_scaling_factors(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mxS_6X7U8nV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIiSXeX3U9GF",
        "outputId": "aae2ed5c-e4a9-4bae-c222-a78ba9efdaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 0 - Weights shape: (50, 784), Biases shape: (50,), Data types: int64, int64\n",
            "Layer 1 - Weights shape: (20, 50), Biases shape: (20,), Data types: int64, int64\n",
            "Layer 2 - Weights shape: (10, 20), Biases shape: (10,), Data types: int64, int64\n",
            "Layer 3 - Weights shape: (10, 10), Biases shape: (10,), Data types: int64, int64\n",
            "Layer 1:\n",
            "  Neuron 1: 0\n",
            "  Neuron 2: 0\n",
            "  Neuron 3: 0\n",
            "  Neuron 4: 1910\n",
            "  Neuron 5: 0\n",
            "  Neuron 6: 0\n",
            "  Neuron 7: 1589\n",
            "  Neuron 8: 0\n",
            "  Neuron 9: 605\n",
            "  Neuron 10: 0\n",
            "  Neuron 11: 0\n",
            "  Neuron 12: 0\n",
            "  Neuron 13: 590\n",
            "  Neuron 14: 0\n",
            "  Neuron 15: 849\n",
            "  Neuron 16: 0\n",
            "  Neuron 17: 0\n",
            "  Neuron 18: 1321\n",
            "  Neuron 19: 1828\n",
            "  Neuron 20: 0\n",
            "  Neuron 21: 0\n",
            "  Neuron 22: 1994\n",
            "  Neuron 23: 0\n",
            "  Neuron 24: 252\n",
            "  Neuron 25: 0\n",
            "  Neuron 26: 1275\n",
            "  Neuron 27: 0\n",
            "  Neuron 28: 249\n",
            "  Neuron 29: 1054\n",
            "  Neuron 30: 0\n",
            "  Neuron 31: 0\n",
            "  Neuron 32: 0\n",
            "  Neuron 33: 0\n",
            "  Neuron 34: 0\n",
            "  Neuron 35: 0\n",
            "  Neuron 36: 254\n",
            "  Neuron 37: 425\n",
            "  Neuron 38: 0\n",
            "  Neuron 39: 1186\n",
            "  Neuron 40: 0\n",
            "  Neuron 41: 107\n",
            "  Neuron 42: 0\n",
            "  Neuron 43: 699\n",
            "  Neuron 44: 0\n",
            "  Neuron 45: 0\n",
            "  Neuron 46: 0\n",
            "  Neuron 47: 2853\n",
            "  Neuron 48: 0\n",
            "  Neuron 49: 132\n",
            "  Neuron 50: 0\n",
            "Layer 2:\n",
            "  Neuron 1: 0\n",
            "  Neuron 2: 0\n",
            "  Neuron 3: 201783\n",
            "  Neuron 4: 185249\n",
            "  Neuron 5: 0\n",
            "  Neuron 6: 277961\n",
            "  Neuron 7: 6241\n",
            "  Neuron 8: 755058\n",
            "  Neuron 9: 0\n",
            "  Neuron 10: 0\n",
            "  Neuron 11: 306923\n",
            "  Neuron 12: 0\n",
            "  Neuron 13: 324755\n",
            "  Neuron 14: 228479\n",
            "  Neuron 15: 132277\n",
            "  Neuron 16: 50859\n",
            "  Neuron 17: 62512\n",
            "  Neuron 18: 71840\n",
            "  Neuron 19: 11705\n",
            "  Neuron 20: 215865\n",
            "Layer 3:\n",
            "  Neuron 1: 70341940\n",
            "  Neuron 2: 0\n",
            "  Neuron 3: 56315637\n",
            "  Neuron 4: 58718372\n",
            "  Neuron 5: 52791201\n",
            "  Neuron 6: 0\n",
            "  Neuron 7: 19502419\n",
            "  Neuron 8: 46791584\n",
            "  Neuron 9: 65073383\n",
            "  Neuron 10: 67623092\n",
            "Layer 4:\n",
            "  Neuron 1: 0\n",
            "  Neuron 2: 0\n",
            "  Neuron 3: 29374245\n",
            "  Neuron 4: 1797733520\n",
            "  Neuron 5: 0\n",
            "  Neuron 6: 193796758\n",
            "  Neuron 7: 0\n",
            "  Neuron 8: 0\n",
            "  Neuron 9: 5031281885\n",
            "  Neuron 10: 3388956740\n",
            "Output: ['0', '0', '29,374,245', '1,797,733,520', '0', '193,796,758', '0', '0', '5,031,281,885', '3,388,956,740']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-104ea4ab2e76>:82: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
            "    * make sure the original data is stored as integers.\n",
            "    * use the `converters=` keyword argument.  If you only use\n",
            "      NumPy 1.23 or later, `converters=float` will normally work.\n",
            "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
            "      floating point and then convert it.  (On all NumPy versions.)\n",
            "  (Deprecated NumPy 1.23)\n",
            "  data = np.loadtxt(input_file, dtype=int)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SimpleNeuron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = np.array(weights, dtype=int)\n",
        "        self.bias = int(bias)\n",
        "\n",
        "    def feedforward(self, inputs):\n",
        "        total = np.dot(self.weights, inputs) + self.bias\n",
        "        return self.activation_function_ReLU(total)\n",
        "\n",
        "    def activation_function_ReLU(self, x):\n",
        "        return max(0, x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layer_config, weights, biases):\n",
        "        self.layers = []\n",
        "        for i in range(len(layer_config) - 1):\n",
        "            layer = []\n",
        "            for j in range(layer_config[i + 1]):\n",
        "                neuron = SimpleNeuron(weights[i][j], biases[i][j])\n",
        "                layer.append(neuron)\n",
        "            self.layers.append(layer)\n",
        "\n",
        "    def feedforward(self, inputs):\n",
        "        for layer_index, layer in enumerate(self.layers):\n",
        "            outputs = []\n",
        "            print(f\"Layer {layer_index + 1}:\")\n",
        "            for neuron_index, neuron in enumerate(layer):\n",
        "                output = neuron.feedforward(inputs)\n",
        "                outputs.append(output)\n",
        "                print(f\"  Neuron {neuron_index + 1}: {output}\")\n",
        "            inputs = outputs\n",
        "        return inputs\n",
        "        # for layer in self.layers:\n",
        "        #     outputs = []\n",
        "        #     for neuron in layer:\n",
        "        #         output = neuron.feedforward(inputs)\n",
        "        #         outputs.append(output)\n",
        "        #     inputs = outputs  # The output of the current layer is the input to the next layer\n",
        "        # return inputs\n",
        "\n",
        "def parse_weights_biases(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    weights = []\n",
        "    biases = []\n",
        "\n",
        "    current_weights = []\n",
        "    current_biases = []\n",
        "    is_weight = False\n",
        "    is_bias = False\n",
        "\n",
        "    for line in lines:\n",
        "        if 'weights' in line:\n",
        "            if current_weights:\n",
        "                weights.append(current_weights)\n",
        "                current_weights = []\n",
        "            is_weight = True\n",
        "            is_bias = False\n",
        "        elif 'biases' in line:\n",
        "            if current_biases:\n",
        "                biases.append(current_biases)\n",
        "                current_biases = []\n",
        "            is_weight = False\n",
        "            is_bias = True\n",
        "        else:\n",
        "            if is_weight:\n",
        "                current_weights.append(list(map(int, map(float, line.strip().split()))))\n",
        "            elif is_bias:\n",
        "                current_biases.append(int(float(line.strip())))\n",
        "\n",
        "    if current_weights:\n",
        "        weights.append(current_weights)\n",
        "    if current_biases:\n",
        "        biases.append(current_biases)\n",
        "\n",
        "    return weights, biases\n",
        "\n",
        "def load_inputs(input_file):\n",
        "    data = np.loadtxt(input_file, dtype=int)\n",
        "    if data.size != 784:\n",
        "        raise ValueError(\"Each input sample must have 784 features\")\n",
        "    return data.reshape(784)\n",
        "\n",
        "file_path = 'quantized_model_quantized_params.txt'\n",
        "weights, biases = parse_weights_biases(file_path)\n",
        "\n",
        "# Reorder the weights and biases based on the layer configuration\n",
        "weights = [np.array(weights[3]), np.array(weights[2]), np.array(weights[1]), np.array(weights[0])]\n",
        "biases = [np.array(biases[3]), np.array(biases[2]), np.array(biases[1]), np.array(biases[0])]\n",
        "\n",
        "# Verify shapes and data types\n",
        "for i, (w, b) in enumerate(zip(weights, biases)):\n",
        "    print(f\"Layer {i} - Weights shape: {w.shape}, Biases shape: {b.shape}, Data types: {w.dtype}, {b.dtype}\")\n",
        "\n",
        "\n",
        "input_file = 'mnist (3).txt'\n",
        "inputs = load_inputs(input_file)\n",
        "\n",
        "layer_config = [784, 50, 20, 10, 10]\n",
        "\n",
        "nn = NeuralNetwork(layer_config, weights, biases)\n",
        "\n",
        "output = nn.feedforward(inputs)\n",
        "formatted_output = [f\"{x:,}\" for x in output]\n",
        "print(f\"Output: {formatted_output}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-mu5xNWCoQ9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ290L1NCoVz",
        "outputId": "7e781dfc-5ba9-4b89-b13a-38f8728ffcf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formatted weights and biases have been written to formatted_weights_biases.txt\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def parse_weights_biases(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    weights = []\n",
        "    biases = []\n",
        "\n",
        "    current_weights = []\n",
        "    current_biases = []\n",
        "    is_weight = False\n",
        "    is_bias = False\n",
        "\n",
        "    for line in lines:\n",
        "        if 'weights' in line:\n",
        "            if current_weights:\n",
        "                weights.append(current_weights)\n",
        "                current_weights = []\n",
        "            is_weight = True\n",
        "            is_bias = False\n",
        "        elif 'biases' in line:\n",
        "            if current_biases:\n",
        "                biases.append(current_biases)\n",
        "                current_biases = []\n",
        "            is_weight = False\n",
        "            is_bias = True\n",
        "        else:\n",
        "            if is_weight:\n",
        "                current_weights.append(list(map(int, map(float, line.strip().split()))))\n",
        "            elif is_bias:\n",
        "                current_biases.append(list(map(int, map(float, line.strip().split()))))\n",
        "\n",
        "    if current_weights:\n",
        "        weights.append(current_weights)\n",
        "    if current_biases:\n",
        "        biases.append(current_biases)\n",
        "\n",
        "    return weights, biases\n",
        "\n",
        "\n",
        "file_path = 'quantized_model_quantized_params (2).txt'\n",
        "weights, biases = parse_weights_biases(file_path)\n",
        "\n",
        "# Reorder the weights and biases based on the layer configuration\n",
        "weights = [np.array(weights[3]), np.array(weights[2]), np.array(weights[1]), np.array(weights[0])]\n",
        "biases = [np.array(biases[3]), np.array(biases[2]), np.array(biases[1]), np.array(biases[0])]\n",
        "\n",
        "layer_config = [784, 50, 20, 10, 10]\n",
        "\n",
        "# Format weights into a list of 2D arrays\n",
        "weights_3d = []\n",
        "for i in range(len(layer_config) - 1):\n",
        "    layer_weights = np.zeros((layer_config[i + 1], layer_config[i]), dtype=int)\n",
        "    for j in range(layer_config[i + 1]):\n",
        "        layer_weights[j] = weights[i][j]\n",
        "    weights_3d.append(layer_weights)\n",
        "\n",
        "# Format biases into a list of 1D arrays\n",
        "biases_2d = []\n",
        "for i in range(len(layer_config) - 1):\n",
        "    layer_biases = np.zeros((layer_config[i + 1], 1), dtype=int)\n",
        "    for j in range(layer_config[i + 1]):\n",
        "        layer_biases[j] = biases[i][j]\n",
        "    biases_2d.append(layer_biases)\n",
        "\n",
        "output_file = 'formatted_weights_biases.txt'\n",
        "\n",
        "with open(output_file, 'w') as f:\n",
        "    f.write(\"parameter int WEIGHTS [][][] = '{\\n\")\n",
        "    for layer_weights in weights_3d:\n",
        "        f.write(\"    '{\\n\")\n",
        "        for neuron_weights in layer_weights:\n",
        "            f.write(\"        '{\" + ', '.join(map(str, neuron_weights)) + \"},\\n\")\n",
        "        f.write(\"    },\\n\")\n",
        "    f.write(\"};\\n\\n\")\n",
        "\n",
        "    f.write(\"parameter int BIASES [][] = '{\\n\")\n",
        "    for layer_biases in biases_2d:\n",
        "        f.write(\"    '{\" + ', '.join(map(str, layer_biases.flatten())) + \"},\\n\")\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "print(f\"Formatted weights and biases have been written to {output_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}